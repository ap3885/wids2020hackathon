{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anany\\Anaconda3\\envs\\envTF113\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\anany\\Anaconda3\\envs\\envTF113\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\anany\\Anaconda3\\envs\\envTF113\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\anany\\Anaconda3\\envs\\envTF113\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\anany\\Anaconda3\\envs\\envTF113\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\anany\\Anaconda3\\envs\\envTF113\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# Load in our libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import tensorflow as tf\n",
    "import sklearn\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt# Load in our libraries\n",
    "import os\n",
    "from sklearn.ensemble import (RandomForestClassifier, AdaBoostClassifier, \n",
    "                              GradientBoostingClassifier, ExtraTreesClassifier)\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./train.csv')\n",
    "test = pd.read_csv('./test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>encounter_id</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>hospital_id</th>\n",
       "      <th>hospital_death</th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>elective_surgery</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>height</th>\n",
       "      <th>...</th>\n",
       "      <th>d1_arterial_po2_min</th>\n",
       "      <th>apache_4a_hospital_death_prob</th>\n",
       "      <th>apache_4a_icu_death_prob</th>\n",
       "      <th>aids</th>\n",
       "      <th>apache_3j_bodysystem</th>\n",
       "      <th>apache_2_bodysystem</th>\n",
       "      <th>gcs_total</th>\n",
       "      <th>cancer</th>\n",
       "      <th>liver_disease</th>\n",
       "      <th>other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>66154</td>\n",
       "      <td>25312</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>3.123686</td>\n",
       "      <td>0</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>180.3</td>\n",
       "      <td>...</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>Sepsis</td>\n",
       "      <td>Cardiovascular</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>114252</td>\n",
       "      <td>59342</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "      <td>3.311273</td>\n",
       "      <td>0</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>160.0</td>\n",
       "      <td>...</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0</td>\n",
       "      <td>Respiratory</td>\n",
       "      <td>Respiratory</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>119783</td>\n",
       "      <td>50777</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>3.464172</td>\n",
       "      <td>0</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>172.7</td>\n",
       "      <td>...</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>Metabolic</td>\n",
       "      <td>Metabolic</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  encounter_id  patient_id  hospital_id  hospital_death  age  \\\n",
       "0           1         66154       25312          118               0   68   \n",
       "1           2        114252       59342           81               0   77   \n",
       "2           3        119783       50777          118               0   25   \n",
       "\n",
       "        bmi  elective_surgery  ethnicity  height  ... d1_arterial_po2_min  \\\n",
       "0  3.123686                 0  Caucasian   180.3  ...                85.0   \n",
       "1  3.311273                 0  Caucasian   160.0  ...                51.0   \n",
       "2  3.464172                 0  Caucasian   172.7  ...                85.0   \n",
       "\n",
       "  apache_4a_hospital_death_prob  apache_4a_icu_death_prob aids  \\\n",
       "0                          0.10                      0.05    0   \n",
       "1                          0.47                      0.29    0   \n",
       "2                          0.00                      0.00    0   \n",
       "\n",
       "   apache_3j_bodysystem  apache_2_bodysystem  gcs_total  cancer  \\\n",
       "0                Sepsis       Cardiovascular         13       0   \n",
       "1           Respiratory          Respiratory          5       0   \n",
       "2             Metabolic            Metabolic         14       0   \n",
       "\n",
       "   liver_disease  other  \n",
       "0              0      1  \n",
       "1              0      1  \n",
       "2              0      0  \n",
       "\n",
       "[3 rows x 59 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummies(train, test):\n",
    "    columns = ['ethnicity', 'hospital_admit_source', 'icu_admit_source', 'icu_type', 'apache_3j_bodysystem', 'apache_2_bodysystem', 'cancer', 'liver_disease', 'other']\n",
    "    for column in columns:\n",
    "        train[column] = train[column].apply(lambda x: str(x))\n",
    "        test[column] = test[column].apply(lambda x: str(x))\n",
    "        good_cols = [column+'_'+i for i in train[column].unique() if i in test[column].unique()]\n",
    "        train = pd.concat((train, pd.get_dummies(train[column], prefix = column)[good_cols]), axis = 1)\n",
    "        test = pd.concat((test, pd.get_dummies(test[column], prefix = column)[good_cols]), axis = 1)\n",
    "        del train[column]\n",
    "        del test[column]\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = dummies(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>encounter_id</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>hospital_id</th>\n",
       "      <th>hospital_death</th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>elective_surgery</th>\n",
       "      <th>height</th>\n",
       "      <th>icu_id</th>\n",
       "      <th>...</th>\n",
       "      <th>cancer_0</th>\n",
       "      <th>cancer_1</th>\n",
       "      <th>cancer_2</th>\n",
       "      <th>cancer_3</th>\n",
       "      <th>liver_disease_0</th>\n",
       "      <th>liver_disease_2</th>\n",
       "      <th>liver_disease_1</th>\n",
       "      <th>other_1</th>\n",
       "      <th>other_0</th>\n",
       "      <th>other_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>66154</td>\n",
       "      <td>25312</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>3.123686</td>\n",
       "      <td>0</td>\n",
       "      <td>180.3</td>\n",
       "      <td>92</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>114252</td>\n",
       "      <td>59342</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "      <td>3.311273</td>\n",
       "      <td>0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>90</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 112 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  encounter_id  patient_id  hospital_id  hospital_death  age  \\\n",
       "0           1         66154       25312          118               0   68   \n",
       "1           2        114252       59342           81               0   77   \n",
       "\n",
       "        bmi  elective_surgery  height  icu_id  ...  cancer_0  cancer_1  \\\n",
       "0  3.123686                 0   180.3      92  ...         1         0   \n",
       "1  3.311273                 0   160.0      90  ...         1         0   \n",
       "\n",
       "   cancer_2  cancer_3  liver_disease_0  liver_disease_2  liver_disease_1  \\\n",
       "0         0         0                1                0                0   \n",
       "1         0         0                1                0                0   \n",
       "\n",
       "   other_1  other_0  other_2  \n",
       "0        1        0        0  \n",
       "1        1        0        0  \n",
       "\n",
       "[2 rows x 112 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anany\\Anaconda3\\envs\\envTF113\\lib\\site-packages\\ipykernel_launcher.py:11: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9224\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(criterion='gini', \n",
    "                             n_estimators=30,\n",
    "                             min_samples_split=3,\n",
    "                             min_samples_leaf=1,\n",
    "                             max_features='auto',\n",
    "                             oob_score=True,\n",
    "                             random_state=1,\n",
    "                             n_jobs=-1)\n",
    "rf.fit(train.loc[:, train.columns != 'hospital_death'], train.loc[:, train.columns == 'hospital_death'])\n",
    "print(\"%.4f\" % rf.oob_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>apache_4a_hospital_death_prob</td>\n",
       "      <td>0.077562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>apache_4a_icu_death_prob</td>\n",
       "      <td>0.067630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>d1_spo2_min</td>\n",
       "      <td>0.034173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>d1_arterial_ph_min</td>\n",
       "      <td>0.031350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>d1_heartrate_min</td>\n",
       "      <td>0.024514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>d1_temp_max</td>\n",
       "      <td>0.024267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>d1_arterial_ph_max</td>\n",
       "      <td>0.023040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>d1_temp_min</td>\n",
       "      <td>0.022024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>heart_rate_apache</td>\n",
       "      <td>0.021308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>d1_wbc_min</td>\n",
       "      <td>0.021067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>d1_platelets_max</td>\n",
       "      <td>0.019709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>pre_icu_los_days</td>\n",
       "      <td>0.019599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>gcs_total</td>\n",
       "      <td>0.019492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>glucose_apache</td>\n",
       "      <td>0.019396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>age</td>\n",
       "      <td>0.019383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>wbc_apache</td>\n",
       "      <td>0.019163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>apache_3j_diagnosis</td>\n",
       "      <td>0.019061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>bmi</td>\n",
       "      <td>0.018874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Unnamed: 0</td>\n",
       "      <td>0.018737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>encounter_id</td>\n",
       "      <td>0.018696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         variable  importance\n",
       "45  apache_4a_hospital_death_prob    0.077562\n",
       "46       apache_4a_icu_death_prob    0.067630\n",
       "22                    d1_spo2_min    0.034173\n",
       "42             d1_arterial_ph_min    0.031350\n",
       "21               d1_heartrate_min    0.024514\n",
       "23                    d1_temp_max    0.024267\n",
       "41             d1_arterial_ph_max    0.023040\n",
       "24                    d1_temp_min    0.022024\n",
       "16              heart_rate_apache    0.021308\n",
       "38                     d1_wbc_min    0.021067\n",
       "32               d1_platelets_max    0.019709\n",
       "9                pre_icu_los_days    0.019599\n",
       "48                      gcs_total    0.019492\n",
       "15                 glucose_apache    0.019396\n",
       "4                             age    0.019383\n",
       "19                     wbc_apache    0.019163\n",
       "11            apache_3j_diagnosis    0.019061\n",
       "5                             bmi    0.018874\n",
       "0                      Unnamed: 0    0.018737\n",
       "1                    encounter_id    0.018696"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat((pd.DataFrame(train.loc[:, train.columns != 'hospital_death'].columns, columns = ['variable']), \n",
    "           pd.DataFrame(rf.feature_importances_, columns = ['importance'])), \n",
    "          axis = 1).sort_values(by='importance', ascending = False)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = rf.predict(test.loc[:, test.columns != 'hospital_death'])\n",
    "predictions = pd.DataFrame(predictions, columns=['hospital_death'])\n",
    "test1 = pd.read_csv(os.path.join('.', 'test.csv'))\n",
    "predictions = pd.concat((test1.loc[:, test1.columns == 'encounter_id'], predictions), axis = 1)\n",
    "predictions.to_csv('y_test15.csv', sep=\",\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anany\\Anaconda3\\envs\\envTF113\\lib\\site-packages\\sklearn\\preprocessing\\label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\anany\\Anaconda3\\envs\\envTF113\\lib\\site-packages\\sklearn\\preprocessing\\label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=None, n=25, n_estimators=100,\n",
       "              n_jobs=1, nthread=None, objective='binary:logistic',\n",
       "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "              seed=None, silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgboost = xgb.XGBClassifier(n = 25)\n",
    "xgboost.fit(train.loc[:, train.columns != 'hospital_death'], train.loc[:, train.columns == 'hospital_death'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgpredictions = xgboost.predict(test.loc[:, test.columns != 'hospital_death'])\n",
    "xgpredictions = pd.DataFrame(xgpredictions, columns=['hospital_death'])\n",
    "test4 = pd.read_csv(os.path.join('.', 'test.csv'))\n",
    "predictions = pd.concat((test4.loc[:, test4.columns == 'encounter_id'], xgpredictions), axis = 1)\n",
    "predictions.to_csv('submission_xgboost.csv', sep=\",\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#creating log directory\n",
    "TENSORBOARD_SUMMARIES_DIR = './tmp/neuralnet_logs'\n",
    "def prepare_log_dir():\n",
    "    '''Clears the log file then creates new directory to place\n",
    "        the tensorbard log file.''' \n",
    "    if tf.gfile.Exists(TENSORBOARD_SUMMARIES_DIR):\n",
    "        tf.gfile.DeleteRecursively(TENSORBOARD_SUMMARIES_DIR)\n",
    "    tf.gfile.MakeDirs(TENSORBOARD_SUMMARIES_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating next batch for training\n",
    "def batch_gen(X,Y,batchsize = 512):\n",
    "    for i in np.arange(0, Y.shape[0], batchsize):\n",
    "        end = min(X.shape[0], i+batchsize)\n",
    "        yield(X[i:end,:],Y[i:end,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create placeholder for X and y and dropout rate\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape = [None,116], name = 'input_data')\n",
    "y = tf.placeholder(tf.float32, shape = [None,2], name = 'input_labels')\n",
    "y_cls = tf.argmax(y,1)\n",
    "\n",
    "discard_rate = tf.placeholder(tf.float32, name='discard_rate')\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model(features):\n",
    "    \n",
    "    #dense layer 1\n",
    "    dense_layer_1 = tf.layers.dense(inputs = features, units = 32, activation = tf.nn.relu)\n",
    "    \n",
    "    #dense layer 3\n",
    "    dense_layer_3 = tf.layers.dense(inputs = dense_layer_1, units = 16, activation = tf.nn.relu)\n",
    "    \n",
    "    #logits layer\n",
    "    logits = tf.layers.dense(inputs = dense_layer_3, units = 2)\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize variables for training\n",
    "epochs = 4\n",
    "num_examples = train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_log_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'ndims'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-69e7b7a26eb3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#predictor model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcnn_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'hospital death'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprediction_cls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#softmax loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-46-efb5b101d08a>\u001b[0m in \u001b[0;36mcnn_model\u001b[1;34m(features)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;31m#dense layer 1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mdense_layer_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m#dense layer 3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\envTF113\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m               \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m               instructions)\n\u001b[1;32m--> 324\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[0;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'deprecated'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\envTF113\\lib\\site-packages\\tensorflow\\python\\layers\\core.py\u001b[0m in \u001b[0;36mdense\u001b[1;34m(inputs, units, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, trainable, name, reuse)\u001b[0m\n\u001b[0;32m    186\u001b[0m                 \u001b[0m_scope\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m                 _reuse=reuse)\n\u001b[1;32m--> 188\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\envTF113\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1225\u001b[0m       \u001b[0mOutput\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m     \"\"\"\n\u001b[1;32m-> 1227\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1229\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mdoc_controls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfor_subclass_implementers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\envTF113\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    528\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    529\u001b[0m       \u001b[1;31m# Actually call layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 530\u001b[1;33m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    531\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    532\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\envTF113\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    536\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m         \u001b[1;31m# Build layer if applicable (if the `build` method has been overridden).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 538\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    539\u001b[0m         \u001b[1;31m# We must set self.built since user defined build functions are not\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;31m# constrained to set self.built.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\envTF113\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   1589\u001b[0m     \u001b[1;31m# Check input assumptions set before layer building, e.g. input rank.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1590\u001b[0m     input_spec.assert_input_compatibility(\n\u001b[1;32m-> 1591\u001b[1;33m         self.input_spec, inputs, self.name)\n\u001b[0m\u001b[0;32m   1592\u001b[0m     \u001b[0minput_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1593\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minput_list\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\envTF113\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    107\u001b[0m         \u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin_ndim\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m         spec.max_ndim is not None):\n\u001b[1;32m--> 109\u001b[1;33m       \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndims\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m         raise ValueError('Input ' + str(input_index) + ' of layer ' +\n\u001b[0;32m    111\u001b[0m                          \u001b[0mlayer_name\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' is incompatible with the layer: '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'ndims'"
     ]
    }
   ],
   "source": [
    "#predictor model\n",
    "prediction = cnn_model(train.loc[:,train.columns != 'hospital death'])\n",
    "prediction_cls = tf.argmax(prediction,1)\n",
    "\n",
    "#softmax loss\n",
    "loss = tf.reduce_mean(tf.losses.softmax_cross_entropy(onehot_labels = train.loc[:,train.columns == 'hospital_death'], logits = prediction))\n",
    "\n",
    "#We use Adam Optimizer\n",
    "optimizer = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68784, 111)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = train.loc[:, train.columns != 'hospital_death']\n",
    "#X = X.loc[:, X.columns != 'encounter ID']              \n",
    "Y = train.loc[:, train.columns == 'hospital_death']\n",
    "Xtrain, Xval, Ytrain, Yval = train_test_split(X, Y, test_size = 0.25, random_state = 42)\n",
    "print(Xtrain.shape)\n",
    "Xtest = test.loc[:, test.columns != 'hospital_death']\n",
    "Ytest = test.loc[:, test.columns == 'hospital_death']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: valid acc = 0.9147441983222961\n",
      "epoch 2: valid acc = 0.9147441983222961\n",
      "epoch 3: valid acc = 0.9147441983222961\n",
      "epoch 4: valid acc = 0.9147441983222961\n",
      "epoch 5: valid acc = 0.9147441983222961\n",
      "epoch 6: valid acc = 0.9147441983222961\n",
      "epoch 7: valid acc = 0.9147441983222961\n",
      "epoch 8: valid acc = 0.9147441983222961\n",
      "epoch 9: valid acc = 0.9147803783416748\n",
      "epoch 10: valid acc = 0.9147803783416748\n",
      "epoch 11: valid acc = 0.9147803783416748\n",
      "epoch 12: valid acc = 0.9147803783416748\n",
      "epoch 13: valid acc = 0.9147803783416748\n",
      "epoch 14: valid acc = 0.9147803783416748\n",
      "epoch 15: valid acc = 0.9147803783416748\n",
      "epoch 16: valid acc = 0.9147803783416748\n",
      "epoch 17: valid acc = 0.9147803783416748\n",
      "epoch 18: valid acc = 0.9147803783416748\n",
      "epoch 19: valid acc = 0.9147803783416748\n",
      "epoch 20: valid acc = 0.9147803783416748\n",
      "epoch 21: valid acc = 0.9147803783416748\n",
      "epoch 22: valid acc = 0.9147803783416748\n",
      "epoch 23: valid acc = 0.9147803783416748\n",
      "epoch 24: valid acc = 0.9147803783416748\n",
      "epoch 25: valid acc = 0.9147803783416748\n",
      "epoch 26: valid acc = 0.9147803783416748\n",
      "epoch 27: valid acc = 0.9147803783416748\n",
      "epoch 28: valid acc = 0.9147803783416748\n",
      "epoch 29: valid acc = 0.9147803783416748\n",
      "epoch 30: valid acc = 0.9147803783416748\n",
      "epoch 31: valid acc = 0.9147803783416748\n",
      "epoch 32: valid acc = 0.9147803783416748\n",
      "epoch 33: valid acc = 0.9147803783416748\n",
      "epoch 34: valid acc = 0.9147803783416748\n",
      "epoch 35: valid acc = 0.9147803783416748\n",
      "epoch 36: valid acc = 0.9147803783416748\n",
      "epoch 37: valid acc = 0.9147803783416748\n",
      "epoch 38: valid acc = 0.9147803783416748\n",
      "epoch 39: valid acc = 0.9147803783416748\n",
      "epoch 40: valid acc = 0.9147803783416748\n",
      "epoch 41: valid acc = 0.9147803783416748\n",
      "epoch 42: valid acc = 0.9147803783416748\n",
      "epoch 43: valid acc = 0.9147803783416748\n",
      "epoch 44: valid acc = 0.9147803783416748\n",
      "epoch 45: valid acc = 0.9147803783416748\n",
      "epoch 46: valid acc = 0.9147803783416748\n",
      "epoch 47: valid acc = 0.9147803783416748\n",
      "epoch 48: valid acc = 0.9147803783416748\n",
      "epoch 49: valid acc = 0.9147803783416748\n",
      "epoch 50: valid acc = 0.9147803783416748\n",
      "epoch 51: valid acc = 0.9147803783416748\n",
      "epoch 52: valid acc = 0.9147803783416748\n",
      "epoch 53: valid acc = 0.9147803783416748\n",
      "epoch 54: valid acc = 0.9147803783416748\n",
      "epoch 55: valid acc = 0.9147803783416748\n",
      "epoch 56: valid acc = 0.9147803783416748\n",
      "epoch 57: valid acc = 0.9147803783416748\n",
      "epoch 58: valid acc = 0.9147803783416748\n",
      "epoch 59: valid acc = 0.9147803783416748\n",
      "epoch 60: valid acc = 0.9147803783416748\n",
      "epoch 61: valid acc = 0.9147803783416748\n",
      "epoch 62: valid acc = 0.9147803783416748\n",
      "epoch 63: valid acc = 0.9147803783416748\n",
      "epoch 64: valid acc = 0.9147803783416748\n",
      "epoch 65: valid acc = 0.9147803783416748\n",
      "epoch 66: valid acc = 0.9147803783416748\n",
      "epoch 67: valid acc = 0.9147803783416748\n",
      "epoch 68: valid acc = 0.9147803783416748\n",
      "epoch 69: valid acc = 0.9147803783416748\n",
      "epoch 70: valid acc = 0.9147803783416748\n",
      "epoch 71: valid acc = 0.9147803783416748\n",
      "epoch 72: valid acc = 0.9147803783416748\n",
      "epoch 73: valid acc = 0.9147803783416748\n",
      "epoch 74: valid acc = 0.9147803783416748\n",
      "epoch 75: valid acc = 0.9147803783416748\n",
      "epoch 76: valid acc = 0.9147803783416748\n",
      "epoch 77: valid acc = 0.9147803783416748\n",
      "epoch 78: valid acc = 0.9147803783416748\n",
      "epoch 79: valid acc = 0.9147803783416748\n",
      "epoch 80: valid acc = 0.9147803783416748\n",
      "epoch 81: valid acc = 0.9147803783416748\n",
      "epoch 82: valid acc = 0.9147803783416748\n",
      "epoch 83: valid acc = 0.9147803783416748\n",
      "epoch 84: valid acc = 0.9147803783416748\n",
      "epoch 85: valid acc = 0.9147803783416748\n",
      "epoch 86: valid acc = 0.9147803783416748\n",
      "epoch 87: valid acc = 0.9147803783416748\n",
      "epoch 88: valid acc = 0.9147803783416748\n",
      "epoch 89: valid acc = 0.9147803783416748\n",
      "epoch 90: valid acc = 0.9147803783416748\n",
      "epoch 91: valid acc = 0.9147803783416748\n",
      "epoch 92: valid acc = 0.9147803783416748\n",
      "epoch 93: valid acc = 0.9147803783416748\n",
      "epoch 94: valid acc = 0.9147803783416748\n",
      "epoch 95: valid acc = 0.9147803783416748\n",
      "epoch 96: valid acc = 0.9147803783416748\n",
      "epoch 97: valid acc = 0.9147803783416748\n",
      "epoch 98: valid acc = 0.9147803783416748\n",
      "epoch 99: valid acc = 0.9147803783416748\n",
      "epoch 100: valid acc = 0.9147803783416748\n",
      "epoch 101: valid acc = 0.9147803783416748\n",
      "epoch 102: valid acc = 0.9147803783416748\n",
      "epoch 103: valid acc = 0.9147803783416748\n",
      "epoch 104: valid acc = 0.9147803783416748\n",
      "epoch 105: valid acc = 0.9147803783416748\n",
      "epoch 106: valid acc = 0.9147803783416748\n",
      "epoch 107: valid acc = 0.9147803783416748\n",
      "epoch 108: valid acc = 0.9147803783416748\n",
      "epoch 109: valid acc = 0.9147803783416748\n",
      "epoch 110: valid acc = 0.9147803783416748\n",
      "epoch 111: valid acc = 0.9147803783416748\n",
      "epoch 112: valid acc = 0.9147803783416748\n",
      "epoch 113: valid acc = 0.9147803783416748\n",
      "epoch 114: valid acc = 0.9147803783416748\n",
      "epoch 115: valid acc = 0.9140205979347229\n",
      "epoch 116: valid acc = 0.9147803783416748\n",
      "epoch 117: valid acc = 0.9147803783416748\n",
      "epoch 118: valid acc = 0.9147803783416748\n",
      "epoch 119: valid acc = 0.9147803783416748\n",
      "epoch 120: valid acc = 0.9147803783416748\n",
      "epoch 121: valid acc = 0.9147803783416748\n",
      "epoch 122: valid acc = 0.9147803783416748\n",
      "epoch 123: valid acc = 0.9147803783416748\n",
      "epoch 124: valid acc = 0.9147803783416748\n",
      "epoch 125: valid acc = 0.9147803783416748\n",
      "epoch 126: valid acc = 0.9147803783416748\n",
      "epoch 127: valid acc = 0.9147803783416748\n",
      "epoch 128: valid acc = 0.9147803783416748\n",
      "epoch 129: valid acc = 0.9147803783416748\n",
      "epoch 130: valid acc = 0.9147803783416748\n",
      "epoch 131: valid acc = 0.9147803783416748\n",
      "epoch 132: valid acc = 0.9147803783416748\n",
      "epoch 133: valid acc = 0.9147803783416748\n",
      "epoch 134: valid acc = 0.9147803783416748\n",
      "epoch 135: valid acc = 0.9147803783416748\n",
      "epoch 136: valid acc = 0.9147803783416748\n",
      "epoch 137: valid acc = 0.9147803783416748\n",
      "epoch 138: valid acc = 0.9147803783416748\n",
      "epoch 139: valid acc = 0.9147803783416748\n",
      "epoch 140: valid acc = 0.9147803783416748\n",
      "epoch 141: valid acc = 0.9147803783416748\n",
      "epoch 142: valid acc = 0.9147803783416748\n",
      "epoch 143: valid acc = 0.9147803783416748\n",
      "epoch 144: valid acc = 0.9147803783416748\n",
      "epoch 145: valid acc = 0.9147803783416748\n",
      "epoch 146: valid acc = 0.9147803783416748\n",
      "epoch 147: valid acc = 0.9147803783416748\n",
      "epoch 148: valid acc = 0.9147803783416748\n",
      "epoch 149: valid acc = 0.9147803783416748\n",
      "epoch 150: valid acc = 0.9147803783416748\n",
      "epoch 151: valid acc = 0.9147803783416748\n",
      "epoch 152: valid acc = 0.9147803783416748\n",
      "epoch 153: valid acc = 0.9147803783416748\n",
      "epoch 154: valid acc = 0.9147803783416748\n",
      "epoch 155: valid acc = 0.9147803783416748\n",
      "epoch 156: valid acc = 0.9147803783416748\n",
      "epoch 157: valid acc = 0.9147803783416748\n",
      "epoch 158: valid acc = 0.9147803783416748\n",
      "epoch 159: valid acc = 0.9147803783416748\n",
      "epoch 160: valid acc = 0.9147803783416748\n",
      "epoch 161: valid acc = 0.9147803783416748\n",
      "epoch 162: valid acc = 0.9147803783416748\n",
      "epoch 163: valid acc = 0.9147803783416748\n",
      "epoch 164: valid acc = 0.9147803783416748\n",
      "epoch 165: valid acc = 0.9147803783416748\n",
      "epoch 166: valid acc = 0.9147803783416748\n",
      "epoch 167: valid acc = 0.9147803783416748\n",
      "epoch 168: valid acc = 0.9147803783416748\n",
      "epoch 169: valid acc = 0.9147803783416748\n",
      "epoch 170: valid acc = 0.9147803783416748\n",
      "epoch 171: valid acc = 0.9147803783416748\n",
      "epoch 172: valid acc = 0.9147803783416748\n",
      "epoch 173: valid acc = 0.9147803783416748\n",
      "epoch 174: valid acc = 0.9147803783416748\n",
      "epoch 175: valid acc = 0.9147803783416748\n",
      "epoch 176: valid acc = 0.9147803783416748\n",
      "epoch 177: valid acc = 0.9147803783416748\n",
      "epoch 178: valid acc = 0.9147803783416748\n",
      "epoch 179: valid acc = 0.9147803783416748\n",
      "epoch 180: valid acc = 0.9147803783416748\n",
      "epoch 181: valid acc = 0.9147803783416748\n",
      "epoch 182: valid acc = 0.9147803783416748\n",
      "epoch 183: valid acc = 0.9147803783416748\n",
      "epoch 184: valid acc = 0.9147803783416748\n",
      "epoch 185: valid acc = 0.9147803783416748\n",
      "epoch 186: valid acc = 0.9147803783416748\n",
      "epoch 187: valid acc = 0.9147803783416748\n",
      "epoch 188: valid acc = 0.9147803783416748\n",
      "epoch 189: valid acc = 0.9147803783416748\n",
      "epoch 190: valid acc = 0.9147803783416748\n",
      "epoch 191: valid acc = 0.9147803783416748\n",
      "epoch 192: valid acc = 0.9147803783416748\n",
      "epoch 193: valid acc = 0.9147803783416748\n",
      "epoch 194: valid acc = 0.9147803783416748\n",
      "epoch 195: valid acc = 0.9147803783416748\n",
      "epoch 196: valid acc = 0.9147803783416748\n",
      "epoch 197: valid acc = 0.9147803783416748\n",
      "epoch 198: valid acc = 0.9147803783416748\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 199: valid acc = 0.9147803783416748\n",
      "epoch 200: valid acc = 0.9147803783416748\n"
     ]
    }
   ],
   "source": [
    "hidden_dim = 100\n",
    "reg_tf = tf.constant(0.01)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "# define a tf.keras.Model class\n",
    "class Model(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.W1 = tf.Variable(1e-2*np.random.rand(111, hidden_dim).astype('float32'))\n",
    "        self.b1 = tf.Variable(np.zeros((hidden_dim,)).astype('float32'))\n",
    "        self.W2 = tf.Variable(1e-2*np.random.rand(hidden_dim, 2).astype('float32'))\n",
    "        self.b2 = tf.Variable(np.zeros((2,)).astype('float32'))\n",
    "    def call(self, inputs):\n",
    "        \"\"\"Run the model.\"\"\"\n",
    "        h1 = tf.nn.relu(tf.matmul(inputs, self.W1) + self.b1)\n",
    "        out = tf.matmul(h1, self.W2) + self.b2\n",
    "        return out\n",
    "\n",
    "# Define and calculate loss function\n",
    "def loss(model, inputs, targets, reg = tf.constant(0.01)):\n",
    "    out = model(inputs)\n",
    "    cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits = out, labels = tf.one_hot(targets,2))\n",
    "    L2_loss = tf.nn.l2_loss(model.W1) + tf.nn.l2_loss(model.W2)\n",
    "    return tf.reduce_mean(cross_entropy) + reg * L2_loss \n",
    "\n",
    "# calculate gradients and do optimization\n",
    "def step(model, inputs, targets, reg = tf.constant(0.01)):\n",
    "    loss_value = loss(model, inputs, targets, reg=reg)\n",
    "    return tf.train.GradientDescentOptimizer(1e-3).minimize(loss_value)\n",
    "\n",
    "# calculate classification accuracy\n",
    "def eval_acc(model, inputs, targets):\n",
    "    correct_prediction = tf.equal(targets, tf.argmax(model(inputs),1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    return accuracy\n",
    "\n",
    "def test_acc(model, inputs, targets):\n",
    "    prediction = model(inputs)\n",
    "    return prediction\n",
    "\n",
    "num_train = 68784\n",
    "batch_size = 2000\n",
    "num_batch = num_train//batch_size\n",
    "num_epochs = 200\n",
    "with tf.Session() as sess:\n",
    "    model = Model()\n",
    "    x_tf = tf.placeholder(tf.float32, shape=(None, 111))\n",
    "    y_tf = tf.placeholder(tf.int64, shape=(None,1))\n",
    "    train_step = step(model, x_tf, y_tf)\n",
    "    accuracy = eval_acc(model, x_tf, y_tf)\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    for e in range(num_epochs):\n",
    "        for i in range(num_batch):\n",
    "            batch_xs, batch_ys = Xtrain[i*batch_size:(i+1)*batch_size], Ytrain[i*batch_size:(i+1)*batch_size]\n",
    "            sess.run(train_step, feed_dict={x_tf: batch_xs, y_tf: batch_ys})\n",
    "        val_acc = sess.run(accuracy, feed_dict={x_tf: Xval, y_tf: Yval})\n",
    "        print('epoch {}: valid acc = {}'.format(e+1, val_acc))\n",
    "    test_accuracy = test_acc(model, x_tf, y_tf)\n",
    "    test_acc = sess.run(test_accuracy, feed_dict={x_tf: Xtest, y_tf: Ytest})\n",
    "    #print('test acc = {}'.format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39308, 112)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.41400412, -0.41400412],\n",
       "       [ 0.41400412, -0.41400412],\n",
       "       [ 0.41400412, -0.41400412],\n",
       "       ...,\n",
       "       [ 0.41400412, -0.41400412],\n",
       "       [ 0.41400412, -0.41400412],\n",
       "       [ 0.41400412, -0.41400412]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
