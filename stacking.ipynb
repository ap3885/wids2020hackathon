{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import sklearn\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt# Load in our libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import sklearn\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from sklearn.ensemble import (RandomForestClassifier, AdaBoostClassifier, \n",
    "                              GradientBoostingClassifier, ExtraTreesClassifier)\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./train.csv')\n",
    "test = pd.read_csv('./test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummies(train, test):\n",
    "    columns = ['ethnicity', 'hospital_admit_source', 'icu_admit_source', 'icu_type', 'apache_3j_bodysystem', 'apache_2_bodysystem', 'cancer', 'liver_disease', 'other']\n",
    "    for column in columns:\n",
    "        train[column] = train[column].apply(lambda x: str(x))\n",
    "        test[column] = test[column].apply(lambda x: str(x))\n",
    "        good_cols = [column+'_'+i for i in train[column].unique() if i in test[column].unique()]\n",
    "        train = pd.concat((train, pd.get_dummies(train[column], prefix = column)[good_cols]), axis = 1)\n",
    "        test = pd.concat((test, pd.get_dummies(test[column], prefix = column)[good_cols]), axis = 1)\n",
    "        del train[column]\n",
    "        del test[column]\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = dummies(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>encounter_id</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>hospital_id</th>\n",
       "      <th>hospital_death</th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>elective_surgery</th>\n",
       "      <th>height</th>\n",
       "      <th>icu_id</th>\n",
       "      <th>...</th>\n",
       "      <th>cancer_0</th>\n",
       "      <th>cancer_1</th>\n",
       "      <th>cancer_2</th>\n",
       "      <th>cancer_3</th>\n",
       "      <th>liver_disease_0</th>\n",
       "      <th>liver_disease_2</th>\n",
       "      <th>liver_disease_1</th>\n",
       "      <th>other_1</th>\n",
       "      <th>other_0</th>\n",
       "      <th>other_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>66154</td>\n",
       "      <td>25312</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>3.123686</td>\n",
       "      <td>0</td>\n",
       "      <td>180.3</td>\n",
       "      <td>92</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>114252</td>\n",
       "      <td>59342</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "      <td>3.311273</td>\n",
       "      <td>0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>90</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 112 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  encounter_id  patient_id  hospital_id  hospital_death  age  \\\n",
       "0           1         66154       25312          118               0   68   \n",
       "1           2        114252       59342           81               0   77   \n",
       "\n",
       "        bmi  elective_surgery  height  icu_id  ...  cancer_0  cancer_1  \\\n",
       "0  3.123686                 0   180.3      92  ...         1         0   \n",
       "1  3.311273                 0   160.0      90  ...         1         0   \n",
       "\n",
       "   cancer_2  cancer_3  liver_disease_0  liver_disease_2  liver_disease_1  \\\n",
       "0         0         0                1                0                0   \n",
       "1         0         0                1                0                0   \n",
       "\n",
       "   other_1  other_0  other_2  \n",
       "0        1        0        0  \n",
       "1        1        0        0  \n",
       "\n",
       "[2 rows x 112 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91713, 112)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some useful parameters which will come in handy later on\n",
    "ntrain = train.shape[0]\n",
    "ntest = test.shape[0]\n",
    "SEED = 0 # for reproducibility\n",
    "NFOLDS = 5 # set folds for out-of-fold prediction\n",
    "kf = KFold(n_splits = NFOLDS, random_state = SEED)\n",
    "\n",
    "# Class to extend the Sklearn classifier\n",
    "class SklearnHelper(object):\n",
    "    def __init__(self, clf, seed=0, params=None):\n",
    "        params['random_state'] = seed\n",
    "        self.clf = clf(**params)\n",
    "\n",
    "    def train(self, x_train, y_train):\n",
    "        self.clf.fit(x_train, y_train)\n",
    "\n",
    "    def predict_proba(self, x):\n",
    "        c1 = self.clf.predict_proba(x)\n",
    "        return c1[:,1]\n",
    "    \n",
    "    def fit(self,x,y):\n",
    "        return self.clf.fit(x,y)\n",
    "    \n",
    "    def feature_importances(self,x,y):\n",
    "        print(self.clf.fit(x,y).feature_importances_)\n",
    "    \n",
    "# Class to extend XGboost classifer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_oof(clf, x_train, y_train, x_test):\n",
    "    oof_train = np.zeros((ntrain,))\n",
    "    oof_test = np.zeros((ntest,))\n",
    "    oof_test_skf = np.empty((NFOLDS, ntest))\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(x_train)):\n",
    "        x_tr = x_train[train_index]\n",
    "        y_tr = y_train[train_index]\n",
    "        x_te = x_train[test_index]\n",
    "\n",
    "        clf.train(x_tr, y_tr)\n",
    "\n",
    "        oof_train[test_index] = clf.predict_proba(x_te)\n",
    "        oof_test_skf[i, :] = clf.predict_proba(x_test)\n",
    "\n",
    "    oof_test[:] = oof_test_skf.mean(axis=0)\n",
    "    return oof_train.reshape(-1, 1), oof_test.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put in our parameters for said classifiers\n",
    "# Random Forest parameters\n",
    "rf_params = {\n",
    "    'n_jobs': -1,\n",
    "    'n_estimators': 100,\n",
    "     'warm_start': True, \n",
    "     #'max_features': 0.2,\n",
    "    'max_depth': 6,\n",
    "    'min_samples_leaf': 2,\n",
    "    'max_features' : 'auto',\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "# Extra Trees Parameters\n",
    "et_params = {\n",
    "    'n_jobs': -1,\n",
    "    'n_estimators':100,\n",
    "    #'max_features': 0.5,\n",
    "    'max_depth': 8,\n",
    "    'min_samples_leaf': 2,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "# AdaBoost parameters\n",
    "ada_params = {\n",
    "    'n_estimators': 100,\n",
    "    'learning_rate' : 0.1\n",
    "}\n",
    "\n",
    "# Gradient Boosting parameters\n",
    "gb_params = {\n",
    "    'n_estimators': 100,\n",
    "     #'max_features': 0.2,\n",
    "    'max_depth': 5,\n",
    "    'min_samples_leaf': 2,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "# Support Vector Classifier parameters \n",
    "#svc_params = {\n",
    "#    'kernel' : 'sigmoid',\n",
    "#    'C' : 0.025,\n",
    "#    'probability' : True\n",
    "#    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Numpy arrays of train, test and target ( Survived) dataframes to feed into our models\n",
    "y_train = train['hospital_death'].ravel()\n",
    "train1 = train.drop(['hospital_death'], axis=1)\n",
    "test1 = test.drop(['hospital_death'], axis=1)\n",
    "x_train = train1.values # Creates an array of the train data\n",
    "x_test = test1.values # Creats an array of the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = SklearnHelper(clf=RandomForestClassifier, seed=SEED, params=rf_params)\n",
    "et = SklearnHelper(clf=ExtraTreesClassifier, seed=SEED, params=et_params)\n",
    "ada = SklearnHelper(clf=AdaBoostClassifier, seed=SEED, params=ada_params)\n",
    "gb = SklearnHelper(clf=GradientBoostingClassifier, seed=SEED, params=gb_params)\n",
    "#svc = SklearnHelper(clf=SVC, seed=SEED, params=svc_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testin 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anany\\Anaconda3\\envs\\envTF113\\lib\\site-packages\\sklearn\\ensemble\\forest.py:307: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n",
      "C:\\Users\\anany\\Anaconda3\\envs\\envTF113\\lib\\site-packages\\sklearn\\ensemble\\forest.py:307: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n",
      "C:\\Users\\anany\\Anaconda3\\envs\\envTF113\\lib\\site-packages\\sklearn\\ensemble\\forest.py:307: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n",
      "C:\\Users\\anany\\Anaconda3\\envs\\envTF113\\lib\\site-packages\\sklearn\\ensemble\\forest.py:307: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing 3\n",
      "testing 4\n",
      "Training is complete\n"
     ]
    }
   ],
   "source": [
    "# Create our OOF train and test predictions. These base results will be used as new features\n",
    "et_oof_train, et_oof_test = get_oof(et, x_train, y_train, x_test) # Extra Trees\n",
    "print(\"testin 2\")\n",
    "rf_oof_train, rf_oof_test = get_oof(rf,x_train, y_train, x_test) # Random Forest\n",
    "print(\"testing 3\")\n",
    "ada_oof_train, ada_oof_test = get_oof(ada, x_train, y_train, x_test) # AdaBoost \n",
    "print(\"testing 4\")\n",
    "gb_oof_train, gb_oof_test = get_oof(gb,x_train, y_train, x_test) # Gradient Boost\n",
    "#print(\"testing 5\")\n",
    "#svc_oof_train, svc_oof_test = get_oof(svc,x_train, y_train, x_test) # Support Vector Classifier\n",
    "\n",
    "print(\"Training is complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.77183251e-03 9.46319152e-04 8.30229972e-04 1.18869890e-03\n",
      " 9.90810102e-03 1.85192531e-03 4.04015717e-03 7.78356259e-04\n",
      " 1.54463958e-03 2.41151372e-03 1.46185977e-02 3.72661006e-02\n",
      " 5.02986611e-03 4.19374369e-05 6.20292953e-03 4.71325260e-03\n",
      " 7.99324309e-03 1.30860069e-02 3.52475978e-02 4.71278252e-03\n",
      " 2.12874427e-03 3.28625903e-02 5.29346278e-02 3.30465846e-02\n",
      " 3.45682478e-02 1.40859696e-02 1.92880903e-03 5.58640111e-03\n",
      " 2.76900736e-03 1.62115021e-03 2.69738030e-03 2.25708282e-03\n",
      " 5.39352727e-03 5.22810252e-03 2.81830754e-03 4.56882148e-03\n",
      " 1.10893914e-03 9.32614457e-03 4.86656259e-03 9.02956854e-03\n",
      " 1.87272072e-02 3.37893912e-02 6.97886780e-02 1.15180191e-02\n",
      " 1.40323068e-02 1.83804762e-01 2.04157524e-01 0.00000000e+00\n",
      " 5.77144241e-02 1.70672469e-04 1.44401432e-05 8.76061166e-06\n",
      " 1.02416322e-04 4.07438673e-05 0.00000000e+00 8.45253006e-05\n",
      " 1.93012977e-04 1.78827958e-04 9.88092544e-04 2.67529193e-04\n",
      " 5.62143977e-05 0.00000000e+00 4.29014734e-05 0.00000000e+00\n",
      " 0.00000000e+00 2.87061953e-05 1.03780022e-04 2.99649131e-06\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 9.12539073e-04\n",
      " 3.97054627e-04 2.92272714e-03 2.71218500e-04 1.95643033e-04\n",
      " 1.40078774e-04 7.98753072e-05 7.03199826e-05 1.04968069e-04\n",
      " 1.51620739e-03 1.19627469e-04 2.37155715e-03 1.63651371e-03\n",
      " 0.00000000e+00 3.74832236e-04 2.12013325e-04 2.17736665e-05\n",
      " 7.16128629e-04 3.80223379e-05 0.00000000e+00 0.00000000e+00\n",
      " 2.42137574e-03 1.21142405e-04 2.18625242e-03 1.10084687e-05\n",
      " 1.99241623e-04 2.15121688e-04 0.00000000e+00 2.07577525e-03\n",
      " 0.00000000e+00 6.60748250e-04 5.61027784e-04 1.10971306e-05\n",
      " 0.00000000e+00 4.26098915e-05 7.91250203e-05 1.25213013e-04\n",
      " 1.60845619e-04 1.61469350e-04 4.02566324e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anany\\Anaconda3\\envs\\envTF113\\lib\\site-packages\\sklearn\\ensemble\\forest.py:307: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8.13786865e-04 3.99349491e-04 5.87860047e-04 7.77109109e-04\n",
      " 1.01004192e-02 8.40343786e-04 1.81126758e-02 5.49303602e-04\n",
      " 8.66198780e-04 8.47210016e-04 9.79386959e-03 1.34201029e-02\n",
      " 1.27597443e-02 4.41705901e-04 5.79951483e-03 3.47121598e-03\n",
      " 8.55654776e-03 4.15755177e-02 8.23754295e-02 5.43604268e-03\n",
      " 1.17221794e-03 1.82631995e-02 4.72212348e-02 1.64314605e-02\n",
      " 4.01025607e-02 1.36959696e-02 2.83129533e-03 5.25860114e-03\n",
      " 2.56533915e-03 1.10382831e-03 2.13277013e-03 1.40602368e-03\n",
      " 5.42404134e-03 5.61375051e-03 4.22971265e-03 5.66781819e-03\n",
      " 9.42024428e-04 8.55339764e-03 6.26873135e-03 6.08683884e-03\n",
      " 1.02954289e-02 2.99344047e-02 4.65083261e-02 6.06985969e-03\n",
      " 5.95690572e-03 1.32583931e-01 1.43344793e-01 1.85346912e-06\n",
      " 1.03342710e-01 5.72651907e-04 1.01403394e-04 2.97446170e-04\n",
      " 4.91845362e-04 1.68524924e-04 1.43985707e-04 4.07352483e-04\n",
      " 1.70953473e-03 1.27046841e-03 4.00134548e-03 9.18223608e-04\n",
      " 3.07664315e-04 2.36916228e-04 1.09030380e-04 3.26854991e-06\n",
      " 1.21838012e-04 1.98297721e-05 6.11765386e-04 1.46355982e-04\n",
      " 3.31259139e-05 1.88049301e-05 0.00000000e+00 5.06302642e-03\n",
      " 2.62258847e-03 1.94324506e-02 5.67592319e-04 1.44071764e-03\n",
      " 9.42006378e-04 5.64413095e-04 5.77262827e-04 4.57563500e-04\n",
      " 9.34325877e-03 9.78507037e-04 8.68405704e-03 9.11448672e-03\n",
      " 1.73069279e-04 1.11260707e-03 1.05393975e-03 2.11961628e-04\n",
      " 5.78570492e-04 5.71150995e-05 8.05356900e-05 1.35092373e-05\n",
      " 1.02832284e-02 2.02873242e-03 8.26826042e-03 3.35386932e-04\n",
      " 1.16276902e-03 1.20604979e-03 1.18345514e-04 9.69177837e-04\n",
      " 9.92796578e-05 4.03979137e-03 2.27163575e-03 8.41484756e-05\n",
      " 0.00000000e+00 1.21270892e-03 5.58405437e-04 2.96229913e-04\n",
      " 7.18922977e-04 8.78560005e-04 1.74770737e-04]\n",
      "[0.   0.   0.   0.   0.07 0.   0.01 0.   0.   0.   0.02 0.04 0.   0.\n",
      " 0.   0.   0.01 0.   0.04 0.   0.   0.1  0.09 0.03 0.04 0.03 0.   0.\n",
      " 0.   0.   0.02 0.   0.04 0.   0.   0.   0.   0.02 0.03 0.   0.04 0.02\n",
      " 0.04 0.   0.   0.12 0.16 0.   0.01 0.   0.   0.   0.   0.   0.   0.\n",
      " 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 0.   0.   0.   0.   0.01 0.   0.   0.   0.   0.   0.   0.   0.01 0.\n",
      " 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      "[8.58194712e-03 2.96107563e-03 3.34094024e-03 4.37199722e-03\n",
      " 1.79736675e-02 8.06558841e-03 1.07739585e-03 3.33041577e-03\n",
      " 5.11636044e-03 7.03527454e-03 5.44128875e-03 1.61547333e-02\n",
      " 3.05306370e-04 3.12638988e-04 1.44798619e-02 5.36908352e-03\n",
      " 1.10852107e-02 1.17830906e-03 4.27922292e-03 3.84500254e-03\n",
      " 6.61065809e-03 5.19812678e-02 5.02679926e-02 2.00477721e-02\n",
      " 1.46227534e-02 7.91870313e-03 3.29066444e-03 3.46282151e-03\n",
      " 3.83971267e-03 2.79506523e-03 3.32241975e-03 3.11411743e-03\n",
      " 1.66207086e-02 2.74024692e-03 7.26363471e-03 1.09182507e-02\n",
      " 2.53170188e-03 8.77923483e-03 1.05662795e-02 9.09954784e-03\n",
      " 1.18320408e-02 2.34827757e-02 2.63090491e-02 5.26513131e-03\n",
      " 8.94563231e-03 3.25711506e-01 2.05385594e-01 0.00000000e+00\n",
      " 1.22651446e-02 0.00000000e+00 5.68302813e-05 1.16977749e-04\n",
      " 3.04119689e-04 0.00000000e+00 0.00000000e+00 2.30169614e-04\n",
      " 6.06444341e-04 2.82652732e-04 0.00000000e+00 7.28334667e-04\n",
      " 1.16178183e-04 5.70028544e-05 1.00836059e-04 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 2.51772064e-04 1.07216448e-04\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 2.84291405e-04\n",
      " 7.52037566e-07 1.00609859e-04 1.74013148e-03 4.37463668e-04\n",
      " 5.66728794e-05 1.02521066e-03 0.00000000e+00 2.06865713e-04\n",
      " 4.21890194e-04 0.00000000e+00 1.08448115e-04 2.47715437e-04\n",
      " 1.85605064e-04 8.51320619e-04 1.05439945e-04 9.60247819e-05\n",
      " 3.14795805e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 2.55189086e-04 0.00000000e+00 1.73512006e-04\n",
      " 1.65208599e-03 1.85615692e-04 5.46353402e-05 0.00000000e+00\n",
      " 0.00000000e+00 1.29716020e-03 4.83810573e-04 1.50568205e-04\n",
      " 0.00000000e+00 0.00000000e+00 6.64513509e-05 1.39277521e-04\n",
      " 9.93335277e-05 1.71678519e-04 0.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "rf_feature = rf.feature_importances(x_train,y_train)\n",
    "et_feature = et.feature_importances(x_train, y_train)\n",
    "ada_feature = ada.feature_importances(x_train, y_train)\n",
    "gb_feature = gb.feature_importances(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>ExtraTrees</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>GradientBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.078155</td>\n",
       "      <td>0.092912</td>\n",
       "      <td>0.445817</td>\n",
       "      <td>0.082193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.410651</td>\n",
       "      <td>0.319828</td>\n",
       "      <td>0.507072</td>\n",
       "      <td>0.780385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.024704</td>\n",
       "      <td>0.024721</td>\n",
       "      <td>0.384096</td>\n",
       "      <td>0.007017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.056990</td>\n",
       "      <td>0.045552</td>\n",
       "      <td>0.429606</td>\n",
       "      <td>0.035800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.027839</td>\n",
       "      <td>0.030305</td>\n",
       "      <td>0.406569</td>\n",
       "      <td>0.012461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RandomForest  ExtraTrees  AdaBoost  GradientBoost\n",
       "0      0.078155    0.092912  0.445817       0.082193\n",
       "1      0.410651    0.319828  0.507072       0.780385\n",
       "2      0.024704    0.024721  0.384096       0.007017\n",
       "3      0.056990    0.045552  0.429606       0.035800\n",
       "4      0.027839    0.030305  0.406569       0.012461"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_predictions_train = pd.DataFrame( {'RandomForest': rf_oof_train.ravel(),\n",
    "     'ExtraTrees': et_oof_train.ravel(),\n",
    "     'AdaBoost': ada_oof_train.ravel(),\n",
    "      'GradientBoost': gb_oof_train.ravel()\n",
    "    })\n",
    "base_predictions_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.concatenate(( et_oof_train, rf_oof_train, ada_oof_train, gb_oof_train), axis=1)\n",
    "x_test = np.concatenate(( et_oof_test, rf_oof_test, ada_oof_test, gb_oof_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm = xgb.XGBClassifier(\n",
    "    #learning_rate = 0.02,\n",
    " n_estimators= 100,\n",
    " max_depth= 4,\n",
    " min_child_weight= 2,\n",
    " #gamma=1,\n",
    " gamma=0.0,                        \n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " nthread= -1,\n",
    " scale_pos_weight=1).fit(x_train, y_train)\n",
    "test['hospital_death'] = 1 - gbm.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tackingSubmission = test[[\"encounter_id\",\"hospital_death\"]].to_csv(\"submission_stacking.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
